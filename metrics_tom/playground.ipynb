{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b67156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import glob\n",
    "import time\n",
    "import timeit\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a08b929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code aims to help you visualize a lived and tracked video and test how changing parameters impact the tracking\n",
    "# Last update (28/03/2025): add a red point to follow the mouse's centroid in the live video\n",
    "\n",
    "\n",
    "input_video = \"/home/tom/Documents/Hackathon_videos/to_15/Video1_TO15.avi\"\n",
    "\n",
    "def track(input_video):\n",
    "\n",
    "    if glob.glob(input_video):\n",
    "        print(\"Video found\")\n",
    "    else:\n",
    "        print(\"No video found, check input_video name\")\n",
    "\n",
    "    # Register the starting time of the function\n",
    "    start = timeit.default_timer()\n",
    "\n",
    "    # Open the video\n",
    "    cap = cv2.VideoCapture(input_video)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "    # Creation of the background subtractor\n",
    "    fgbg = cv2.createBackgroundSubtractorMOG2(\n",
    "        history=1, varThreshold=16, detectShadows=True\n",
    "    )\n",
    "\n",
    "    # Initialize position and time\n",
    "    time_arr, x_pos, y_pos = np.array([]), np.array([]), np.array([])\n",
    "    \n",
    "    t = 0\n",
    "\n",
    "    # Retrieving framerate and frame count\n",
    "    resolution = 512, 512\n",
    "    framerate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) - framerate\n",
    "\n",
    "    # Variable for break\n",
    "    pause = False\n",
    "\n",
    "    # Window Initialization\n",
    "    # The video + tracking will be displayed in this window\n",
    "    cv2.namedWindow(\"Original (left) | Tracked (right)\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "    # Resize the window to a specific size (e.g. 1024x512)\n",
    "    window_width = 1024  # Window width\n",
    "    window_height = 512  # Window heigh\n",
    "    cv2.resizeWindow(\n",
    "        \"Original (left) | Tracked (right)\", window_width, window_height\n",
    "    )\n",
    "\n",
    "    # Frame processing loop\n",
    "    for _ in range(0, length):\n",
    "\n",
    "        # If the video is paused, we wait\n",
    "        while pause:\n",
    "            k = cv2.waitKey(50) & 0xFF  # Waiting to avoid infinite loop\n",
    "            if k == ord(\" \"):  # Press \"Space\" to resume\n",
    "                pause = False\n",
    "\n",
    "        # Register the time at which the current frame starts to be processed\n",
    "        frame_start = time.time()\n",
    "\n",
    "        # Read current frame\n",
    "        ret, frm = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        ##################################\n",
    "        ### Mouse detection + tracking ###\n",
    "        ##################################\n",
    "        \n",
    "        # Resize current frame\n",
    "        frm = cv2.resize(frm, resolution, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Apply a Gaussian blur (not sure if it is necessary ? Maybe it's better for the background substraction)\n",
    "        kernelSize = (25, 25)\n",
    "        frameBlur = cv2.GaussianBlur(frm, kernelSize, 0)\n",
    "\n",
    "        # Apply background subtraction\n",
    "        thresh = fgbg.apply(frameBlur, learningRate=0.0009)\n",
    "\n",
    "        # Calculation of the centroid (center of mass). This will be considered as the position of the mouse.\n",
    "        M = cv2.moments(thresh)\n",
    "        if M[\"m00\"] == 0:\n",
    "            continue\n",
    "\n",
    "        x = int(M[\"m10\"] / M[\"m00\"])\n",
    "        y = int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "        # Draw a red dot on the centroid\n",
    "        cv2.circle(\n",
    "            frm, (x, y), 10, (0, 0, 255), -1\n",
    "        )  # Center (x, y), radius 10, color red (0, 0, 255), fill (-1)\n",
    "\n",
    "        # Save positions and timestamps\n",
    "        t += 1 / framerate\n",
    "        time_arr = np.append(time_arr, t)\n",
    "        x_pos = np.append(x_pos, x)\n",
    "        y_pos = np.append(y_pos, y)\n",
    "\n",
    "        #######################################\n",
    "        ### Display of the video + tracking ###\n",
    "        #######################################\n",
    "\n",
    "        # Concatenate videos: Original on the left, tracked on the right\n",
    "        thresh_colored = cv2.cvtColor(thresh, cv2.COLOR_GRAY2BGR)\n",
    "        combined = cv2.hconcat(\n",
    "            [frm, thresh_colored]\n",
    "        )  # Fusionner les deux vid√©os\n",
    "\n",
    "        # Adjust the size of the concatenated image to fill the window without distortion\n",
    "        combined_resized = cv2.resize(\n",
    "            combined,\n",
    "            (window_width, window_height),\n",
    "            interpolation=cv2.INTER_AREA,\n",
    "        )\n",
    "\n",
    "        # Show the combined video in one window\n",
    "        cv2.imshow(\"Original (left) | Tracked (right)\", combined_resized)\n",
    "\n",
    "        # Processing time\n",
    "        frame_end = time.time()\n",
    "        frame_processing_time = frame_end - frame_start\n",
    "\n",
    "        # Calculating waiting time\n",
    "        wait_time = max(\n",
    "            1, int((1000 / framerate) - (frame_processing_time * 1000))\n",
    "        )\n",
    "\n",
    "        # Manage keyboard inputs\n",
    "        k = cv2.waitKey(wait_time) & 0xFF\n",
    "        if k == ord(\"q\"):  # Quit\n",
    "            break\n",
    "        elif k == ord(\" \"):  # Break\n",
    "            pause = True\n",
    "\n",
    "    # Close the window and free the memory\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    stop = timeit.default_timer()\n",
    "    print(\"Time: \", stop - start)\n",
    "\n",
    "    return(x_pos, y_pos, time_arr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
